\documentclass{ctexart}

% Language setting
% Replace `english' with e.g. `spanish' to change the document language
% \usepackage{authblk}
\usepackage[english]{babel}

% Set page size and margins
% Replace `letterpaper' with`a4paper' for UK/EU standard size
\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}

\title{统计建模与深度学习思潮：统计大讲堂心得体会}
\author{苏锦华 2021103740}


\begin{document}
\maketitle



\section{引言}

与单纯的课业学习不同，当真正开始思考做研究、甚至做有贡献的事情后，才发现评价标准和路径的多样化。主文献阅读以及统计大讲堂给我带来一些冲击，也带来一些思考的动机，思考的内容则可能已经脱离了课业的舒适圈，更多的部分来源于实践。关于如何解决问题的范畴显得过大，利用统计学的知识进行建模真实地解决实际问题这个话题我希望能借此机会认真思考。在经历过数次解决实际问题的过程中统计建模方法受挫，并在深度学习算法中极其容易地获取到行之有效的方案后，自己对于是否复杂统计建模方法才能有效的判断越来越没有底气。

比较幸运的是，我大概成了半个贝叶斯拥护者加半个深度学习伸手党，在统计大讲堂的讲座群后我更加认清了统计建模革新不可阻挡。我感兴趣并且参与的讲座中，有一半以上并不避讳地介绍着并非经典概率建模的“统计方法”，无论究竟是否是统计建模的历史遗物，一些深度学习的“舶来词”已经比统计学里的表述更加流行。“不平衡学习”、“稳定学习”等新词已经对于统计学讲座来说变得并不陌生，抽样、检验、估计等统计特色问题也相对出现地少了，不可否认，深度学习的思潮已经影响着数目可观的统计学研究者。当然先抛开结论说现象，精算、基因、医药等统计建模的应用领域对深度学习的新方法已经是持支持甚至大步向前看的态度，Quan老师分享如何树模型中修正损失以满足精算需求，李向杰老师分享空间转录组数据应用图卷积网络的案例，显示出应用学科对新方法兼收并蓄的特点。不管是否是出于分一杯羹或者赶时髦的目的，研究者开展相关交叉研究的积极性火热，那如何认识深度学习与统计建模的关系不可回避。

当然这也并非只有研究者所面临的问题，数据科学、人工智能的目标从业者，甚至所有曾经涉及统计建模或者算法研究相关岗位都需要思考的问题：从建模使用的角度考虑，孰优孰劣，何去何从？本心得主要围绕着数据、算法和仿生这三种文化，以及对待不同统计建模与深度学习的交叉领域开展研究时值得一试的几种主义，最后是对统计建模新形态或深度学习新框架的展望。

\section{三种文化}

两种文化即传统统计建模所关注的数据文化和深度学习所关注的算法文化，本章节的观点主要来自Leo Breiman在2001年的经典文章《统计建模：两种文化》和笔者本人的一些感悟。当然20年过去，除了数据和算法文化，深度学习的大行其道不得不提其仿生学文化，可以说预训练方法以及参数巨量化都可以看出人工智能算法的发展离不开对人类智能或则说人脑的崇拜。毕竟AlphaGo背后的深度强化学习的决策理论，用数据文化和算法文化似乎都没法概括，其背后的文化怎样也无法绕开达尔文主义。因为迭代文化在统计学早已存在，取仿生学更有对崇拜意味，与深度学习所被诟病的黑箱更加契合。

统计学关注数据，是数据文化。对数据的假设是建模的出发之道，而且出于待估参数量精简化的“统计之美”癖好，或者追求某种“Most”、“Uniformly”或“Gradually”性质，“i.i.d”或者“马氏链”的独立性假设是常客，“高斯正态”、“共轭”等优等分布族更是罪恶之源。但不得不说，在小样本小数据场景下，很多时候能够优雅地奏效。

数据假设的强弱利弊从2010年就暴露，也正好是机器学习概念热度兴起之时，可以说机器学习方法在统计决策的框架下，但其算法本身的构思存在浓厚的算法色彩，也就是有明显不同于统计学场景的变量或者噪音服从某一分布的假设。受限于数据收集与存储的限制，可以说很多情况下这样假设也无可厚非。然而，当数据的复杂程度开始上涨，其内在的生成结构与逻辑可能会变得非常复杂，从而与简单的假设分道扬镳。

如果仔细思考算法发展的方向，就会发现它往往需要一个标签数据集来训练算法，然后评估算法在另一个数据集上的 “准确率” 作为核心指标。仔细思考，与X、y平等建模的数据文化不同的是，算法文化从X中筛选特征，过度重视y实际上是一步一步将路走窄。很多论文工作在公开数据集所努力提高的一两分也许只是向广义上的“过拟合”所前进（狭义上的过拟合被验证集与测试集的设计所规避了），可能在牺牲模型在相似任务上的泛用性。损失的这种泛用性很可能带来极大的安全隐患，比如带上特制眼镜可以攻击人脸识别算法使之得到完全不同的结果。

如果再考虑近五年来预训练模型的泛滥和NAS（神经网络结构搜索）所用的现代优化算法（遗传、蚁群、退火）的兴起，不难看出仿生作为一种绝妙而令人敬畏的思想将继续指导算法的演化方向。但仿生的思想要么过于简单通俗、要么过于实践困难，并不在笔者的重点讨论内容内，依旧回到数据文化和算法文化的主流思潮中。

数据文化使用过分简单的假设导致不够实用，算法尽可能的放弃假设，利用大量标注数据来驱动模型导致成本高昂同时面临广义“过拟合”的风险。那么，我们能不能在设计算法的同时加入一些对数据的假设呢？ 其实这个做法长久以来都作为算法设计的一个重要的组成部分，但是最近算法的弱点越来越明显，大家对此的关注也逐渐升温，如物理AI、根据图像任务实际的光学物理性质进行约束、对于任务本身和数据性质进行研究提出最合适的数据增强方法和对比学习策略。

我们需要一个新的文化来应对这个新的挑战，而这个新的文化在上述例子中已经有了雏形。从这里孵化出的工作应当首先对数据产生的机制有深刻的理解，同时能够把这个产生机制在计算上表示出来。 这样的表示与经典数据文化里只局限在统计分布上的假设相比，虽然也许更难分析其数学性质，但是也更灵活，从而让使用者能主动针对不同的数据与任务作出不同的合理假设。在这样的表示之上，算法设计往往可以变得更简单，计算效率与数据利用效率可能也更高效。显然这样的工作是还不够的，那么我们如何进行数据文化和算法文化的交叉研究，笔者在这里提出和讨论几种主义，可供尝试。


\section{几种主义}

不同统计研究者尝试做深度学习相关的交叉工作切入点不同，采用的交叉研究思路也不同，交叉工作的交叉程度也不一样。比如10\%统计+90\%深度学习、90\%统计+10\%深度学习是比较轻度的结合，两者框架和思想不同，深度融合是比较困难，研究也比较有突破性。比如崔鹏老师的对于稳定性、可解释性、公平性和可回溯性的不足，提出利用因果统计代替关联统计融入机器学习框架，就有对深度学习和统计理论的深刻洞见。当然并不是所有交叉工作都需要从底层做起，也可以对特定缺陷进行修正，或者结合统计学模型在可解释性上的优势做部分权衡调整的工作。

对于不同的交叉工作可以按照方法和任务进行划分，当然方法或者任务都可能存在混合的情况，即10\%统计+90\%深度学习就属于简单混合，简单混合以占主要地位的方法和任务来衡量，当然目标都是深度交叉为目标，即50\%统计+50\%深度学习优劣势互补是我们追求的。1.对于研究典型统计问题，主要方法框架也是成熟优美的统计方法的情况（假设检验、区间估计），可以尝试拿来主义来打破固有认知，尽可能替换原有框架，当然受制于统计问题的特殊性要求，增加深度学习组件和技巧仍然很难打破统计建模的主导地位，因为统计建模的目标对于性质有较高的需求；2.而对于因果推断、时序分析等较为复杂而发展较晚的统计任务，已有统计方法做了过多不同于现实情况的复杂假设，同时数据量也难以支撑大数条件下的优良性质，深度学习方法就有机可乘了，这时候可以尝试返璞归真，回归问题本身的关键难点，使用深度学习的方法重新建模，当然过程中可以参考已有统计方法的核心思想；3.对于复杂数据结构，如图像、文本等本来就是统计模型简单假设难以解决的场景，属于深度学习场景，但难以解决不代表统计建模无计可施，可以尝试“守正出奇”的思想，保持常规统计建模框架的同时，尝试深度学习的思想，比如深度学习堆参数，那可以尝试深度贝叶斯图模型，如果深度学习分batch使用随机梯度下降来加快训练速度，可以尝试随机变分推断（SVI）来进行参数估计。4.对于深度学习场景但是深度学习已经完美解决甚至工业成熟的场景，比如人脸识别，可以尝试修正主义，在保持方法不变和数据不变的场景下选择偏门的相关问题，尝试提供即插即用的可解释性工具或数据增强方法。


图卷积和标签传播算法的等同性

\begin{table}[]
      \begin{tabular}{lllll}
      \cline{2-3}
      \multicolumn{1}{l|}{}             & \multicolumn{1}{l|}{典型统计建模思想方法}          & \multicolumn{1}{l|}{典型深度学习思想算法}        &  &  \\ \cline{1-3}
      \multicolumn{1}{|l|}{典型统计建模任务}   & \multicolumn{1}{l|}{1.拿来主义（假设检验、区间估计）}   & \multicolumn{1}{l|}{2.返璞归真（因果、时序）}   &  &  \\ \cline{1-3}
      \multicolumn{1}{|l|}{典型深度学习任务} & \multicolumn{1}{l|}{3.守正出奇（SVI和深度贝叶斯学习）} & \multicolumn{1}{l|}{4.修正主义（可解释工具）} &  &  \\ \cline{1-3}
                                        &                                        &                                        &  & 
      \end{tabular}
      \end{table}

\section{路径依赖与何去何从}

能不能做出50\%统计+50\%深度学习算法的东西，还是从浅层结合开始其实是有路径依赖。对于研究方向和知识体系结构尚未确定的研究初探者，统计计算是一个较好入门的切入口，对于掌握不同的统计模型可以从底层实现进行深度优化，甚至可以说速度和迭代是统计学与深度学习两种文化的重大差异。统计到数据科学的学科培养少不了工具的提升，工程化的能力是统计入门深度学习的最大阻碍，所以重视统计计算，是一个难得的技能培养点。

对于统计建模与深度学习的交叉是不可阻挡的，对于相关职业的何去何从也是可预见的。不可否认，当前深度学习的热潮培养了一批模型调参工程师，但回归本质算法工程师需要找到观察再建模。对模型调参能力也将逐渐转变为数据观察能力，理解数据、认识数据的目的是为了克服数据的缺陷更好地服务于建模最终目标，自监督、对比学习、多目标学习任务的设计也是一种数据建模。



\bibliographystyle{alpha}
\bibliography{sample}

\end{document}